# **RaCalNet: Radar Calibration Network for Sparse-Supervised Dense Depth Estimation**

## 1. Overview

RaCalNet is a novel framework for dense depth estimation using millimeter-wave (mmWave) radar and monocular RGB images, designed to eliminate the reliance on costly dense LiDAR supervision. Unlike previous methods that require dense pseudo ground-truth generated via multi-frame LiDAR fusion and interpolation, RaCalNet learns from sparse single-frame LiDAR, reducing supervision density to just ~1% while maintaining high accuracy.

RaCalNet is composed of two main components:
<p align="center"> <img src="./figs/system.png" alt="RaCalNet System Overview" width="90%"> </p>

ğŸ¯ Radar Recalibration Module
Selects high-quality radar points and refines them through pixel-wise displacement learning, producing reliable, fine-grained depth priors.

ğŸ“ Metric Depth Optimization Module
Uses the refined radar priors to calibrate monocular depth predictions by estimating scene-level scale and shift, yielding metrically accurate dense depth maps.

<p align="center"> <img src="./figs/zju_result.png" alt="RaCalNet Qualitative Results" width="90%"> </p>
Despite relying only on sparse supervision, RaCalNet produces high-quality depth maps with clear object contours and fine-grained geometric details, as shown in the qualitative example above.


## 2.RaCalNet Release Checklist

This checklist outlines the planned public releases for the RaCalNet project.

âœ… Planned Releases

- [ ] ğŸ« **Release our self-collected 4D mmWave radar dataset in campus scenes**

- [ ] ğŸ“ **Release the calibrated ZJU-4DRadarCam dataset**
  - Includes refined sensor extrinsics and consistent projection quality

- [ ] ğŸ§  **Release the inference code of RaCalNet**
  - Support for single-frame RGB + Radar input
  - Easy-to-use script for depth map generation

- [ ] ğŸ§¾ **Release pretrained model weights**
  - Trained on the calibrated ZJU-4DRadarCam dataset
  - Includes instructions for evaluation and benchmarking
